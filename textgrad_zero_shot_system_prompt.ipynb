{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 使用 Textgrad 最佳化 system prompt 🏆\n",
        "\n",
        "\n",
        "\n",
        "這個 Notebook 使用 https://textgrad.com/ 進行 system prompt 的最佳化\n",
        "\n",
        "* 輸入你的任務描述\n",
        "* 就能產出很厲害 zero-shot prompt\n",
        "* 用在沒有標準答案的場景，採用 LLM 自動評估\n",
        "\n",
        "作者和演講投影片: ihower https://ihower.tw/blog/archives/12444\n",
        "\n",
        "### 流程\n",
        "\n",
        "1. 使用 o1-preview 合成訓練問題\n",
        "2. 使用 gpt-4o 進行 textgrad 最佳化，採用 LLM-as-a-judge 自動化評估\n",
        "3. 產生適合 gpt-4o-mini 的 system prompt\n",
        "\n",
        "成本: 最佳化迭代大約要花5分鐘，耗費 USD 0.8 美金 (10個訓練範例)"
      ],
      "metadata": {
        "id": "7Jo0Dea0J6o7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 設定 OpenAI API key"
      ],
      "metadata": {
        "id": "W9B_btTuLCi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "請點 google colab 左邊側欄的鑰匙符號，新增密鑰，名稱是 openai_api_key，值就填 API key"
      ],
      "metadata": {
        "id": "PV3zId96LEsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "import json\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api_key')"
      ],
      "metadata": {
        "id": "7balGFjoLBdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 設定參數"
      ],
      "metadata": {
        "id": "odBHM6mtKNRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_model = \"o1-preview\" # 合成訓練問題的模型，若你沒有 o1 權限，請改用 gpt-4o\"\n",
        "generation_model = \"gpt-4o\" # 合成 prompt 的模型\n",
        "prediction_model = \"gpt-4o-mini\" # 用來執行 prompt 的模型\n",
        "\n",
        "task_description = \"根據用戶輸入的專業領域，條列其中的關鍵知識重點\" # 任務描述，請修改成你的任務\n",
        "\n",
        "questions_num = 10  # 要合成多少訓練資料，跟花費的 API 成本有關，建議不要再少了，會 overfitting\n",
        "\n",
        "# 用來評估答案好不好的 prompt，可以改，但請保留 [question_string] 字串\n",
        "eval_prompt_template = \"\"\"Here's a question: [question_string].\n",
        "Evaluate any given answer to this question, be smart, logical, and very critical.\n",
        "Just provide concise feedback.\"\"\""
      ],
      "metadata": {
        "id": "Kn3CV3b_KDUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 合成最佳化需要的 dataset\n"
      ],
      "metadata": {
        "id": "BiEGAbY4IztH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_prompt = f\"\"\"You are tasked with creating a test dataset for an AI question-answering system. Your goal is to generate {questions_num} example questions based on a given task description. These questions should range from simple to complex, with the more difficult questions requiring reasoning and presenting a significant challenge.\n",
        "Here are the guidelines for generating the questions:\n",
        "\n",
        "Start with simple, straightforward questions and gradually increase the complexity.\n",
        "Ensure that the more difficult questions require multi-step reasoning or in-depth knowledge.\n",
        "Include a variety of question types (e.g., factual, analytical, hypothetical) relevant to the task description.\n",
        "Ensure that all questions are directly related to the provided task description.\n",
        "\n",
        "The task description you should base your questions on is as follows:\n",
        "<task_description>\n",
        "{task_description}\n",
        "</task_description>\n",
        "\n",
        "Please generate {questions_num} example questions based on this task description. Format your output as a JSON array of objects, where each object contains a 'question' key with the question text as its value, and an 'answer' key with the answer text as its value. The output should look like this:\n",
        "[\n",
        "{{\"question\": \"Question 1 text here\", \"answer\": \"Answer 1 text here\"}},\n",
        "{{\"question\": \"Question 2 text here\", \"answer\": \"Answer 2 text here\"}},\n",
        "...\n",
        "]\n",
        "\n",
        "Remember to increase the difficulty and complexity of the questions as you progress through the examples. The final few questions should be particularly challenging, requiring complex reasoning and demonstrating a high level of difficulty.\"\"\""
      ],
      "metadata": {
        "id": "JMjKvsE3CuJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install litellm\n",
        "\n",
        "from litellm import completion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78T5L9i9D45D",
        "outputId": "ce704ea9-b50b-463b-a5d1-9e708529e58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting litellm\n",
            "  Downloading litellm-1.46.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm) (3.10.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (4.23.0)\n",
            "Collecting openai>=1.45.0 (from litellm)\n",
            "  Downloading openai-1.45.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (2.9.1)\n",
            "Collecting python-dotenv>=0.2.0 (from litellm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (2.32.3)\n",
            "Collecting tiktoken>=0.7.0 (from litellm)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm) (0.19.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.20.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->litellm) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.45.0->litellm) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.45.0->litellm)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.45.0->litellm)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->litellm) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->litellm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->litellm) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.23.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (2024.8.30)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.7.0->litellm) (2024.5.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (4.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm) (0.24.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.45.0->litellm) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.45.0->litellm)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.45.0->litellm)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
            "Downloading litellm-1.46.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.45.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.1/374.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, jiter, h11, tiktoken, httpcore, httpx, openai, litellm\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 litellm-1.46.0 openai-1.45.0 python-dotenv-1.0.1 tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    { \"content\": synthetic_prompt, \"role\": \"user\"}\n",
        "]\n",
        "\n",
        "if not synthetic_model.startswith('o1'):\n",
        "  response = completion(model=synthetic_model, messages=messages, response_format={ \"type\": \"json_object\" })\n",
        "else:\n",
        "  # o1 目前還不支援 json mode\n",
        "  response = completion(model=synthetic_model, messages=messages)\n",
        "\n",
        "response = response.choices[0].message.content\n",
        "dataset = json.loads(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvULyE7CD8ED",
        "outputId": "b5e1bf80-501f-41ad-8fb6-1af0be19325a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/main.py:387: UserWarning: Pydantic serializer warnings:\n",
            "  Expected `CompletionTokensDetails` but got `dict` with value `{'reasoning_tokens': 4480}` - serialized value may not be as expected\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejQqTthWFsdR",
        "outputId": "48eff436-50c9-49b6-e98b-f8ee22a7dae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question': '1. 这个任务的主要目标是什么？', 'answer': '根据用户输入的专业领域，列出其中的关键知识重点。'},\n",
              " {'question': '2. 如果用户输入“计算机科学”作为专业领域，应该列出哪些关键知识点？',\n",
              "  'answer': '计算机科学的关键知识点包括算法、数据结构、计算机组成原理、操作系统、编程语言、数据库、网络、软件工程原理和人工智能等。'},\n",
              " {'question': '3. 如何判断某个知识点在一个专业领域内是关键的？',\n",
              "  'answer': '可以根据其基础性、对多个子领域的相关性、在专业中使用的频率、作为高级主题的前提条件的作用，以及其在标准课程和认证中的包含情况来判断。'},\n",
              " {'question': '4. 如何确保列出的关键知识点清单是全面且准确的？',\n",
              "  'answer': '可以参考权威来源，如学术课程、行业标准、专业指南、教科书、专家意见，并通过交叉检验多个可信资源来验证每个知识点的重要性。'},\n",
              " {'question': '5. 描述一种将专业领域的关键知识点进行结构化组织的方法。',\n",
              "  'answer': '一种方法是将知识点分类到该专业的主要领域或子领域，按照从一般到具体的层次结构排列，或根据主题、概念或能力进行分组，以提供逻辑性的结构。'},\n",
              " {'question': '6. 为什么根据用户的特定需求或背景定制关键知识点列表很重要？',\n",
              "  'answer': '因为不同的用户可能具有不同的专业水平、具体兴趣或特定应用，定制列表可以提高其相关性和实用性，增强其有效性和适用性。'},\n",
              " {'question': '7. 如果要为一个资源有限的专业小众领域列出关键知识点，你将如何着手？',\n",
              "  'answer': '我会联系该领域的专家，审阅任何可用的文献或案例研究，分析相关的更广泛的领域以寻找重叠的知识点，并利用专业人士讨论相关主题的在线社区或论坛。'},\n",
              " {'question': '8. 讨论在识别跨学科专业领域的关键知识点时可能遇到的挑战，以及如何克服它们。',\n",
              "  'answer': '挑战包括整合多个学科的概念的复杂性、术语或方法论的潜在冲突，以及所需知识的广度。克服这些挑战需要深入研究，与各学科专家合作，仔细综合信息，突出最关键的交叉点。'},\n",
              " {'question': '9. 如何验证所识别的关键知识点是最新的，反映了专业领域的当前趋势和进展？',\n",
              "  'answer': '可以通过审阅最新出版物、参加专业会议、关注行业新闻和更新、咨询当代专家，以及检查该领域权威机构发布的最新标准或最佳实践来进行验证。'},\n",
              " {'question': '10. 提出一个系统的方法来开发一个算法或工具，能够为任何给定的专业领域生成关键知识点列表，详细说明所涉及的步骤以及如何应对各种挑战。',\n",
              "  'answer': '一个系统的方法可能包括：\\n\\n1. **输入分析**：接受专业领域作为输入，标准化术语，识别相关的关键词。\\n\\n2. **数据收集**：从权威来源收集数据，如专业协会、学术机构和行业出版物。\\n\\n3. **知识提取**：使用自然语言处理从收集的数据中提取潜在的知识点。\\n\\n4. **相关性过滤**：应用标准评估每个知识点的重要性，如提及频率、在领域中的核心地位和专家验证。\\n\\n5. **分类整理**：将知识点组织成逻辑类别和层次结构，以便更好地理解。\\n\\n6. **持续更新**：实施反馈机制，持续用新信息更新列表，删除过时的知识点。\\n\\n这种方法通过利用数据驱动的方法和专家输入，确保生成的知识点准确、相关且及时，从而应对各种挑战。'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 使用 Textgrad 最佳化 system prompt"
      ],
      "metadata": {
        "id": "q_IQhxwaFhDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textgrad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsPYE348Bjxm",
        "outputId": "f353b3dc-d1d1-45b8-f57f-2779db5a0204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textgrad\n",
            "  Downloading textgrad-0.1.5.tar.gz (65 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m61.4/65.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: openai>=1.23.6 in /usr/local/lib/python3.10/dist-packages (from textgrad) (1.45.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from textgrad) (9.0.0)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from textgrad) (1.0.1)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from textgrad) (2.1.4)\n",
            "Requirement already satisfied: platformdirs>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from textgrad) (4.3.2)\n",
            "Collecting datasets>=2.14.6 (from textgrad)\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting diskcache>=5.6.3 (from textgrad)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: graphviz>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from textgrad) (0.20.3)\n",
            "Collecting gdown>=5.2.0 (from textgrad)\n",
            "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from textgrad) (9.4.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from textgrad) (0.27.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->textgrad) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->textgrad) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=2.14.6->textgrad)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->textgrad)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->textgrad) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->textgrad) (4.66.5)\n",
            "Collecting xxhash (from datasets>=2.14.6->textgrad)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets>=2.14.6->textgrad)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.14.6->textgrad) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->textgrad) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->textgrad) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->textgrad) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.14.6->textgrad) (6.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=5.2.0->textgrad) (4.12.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.23.6->textgrad) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.23.6->textgrad) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.23.6->textgrad) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.23.6->textgrad) (2.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.23.6->textgrad) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.23.6->textgrad) (4.12.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->textgrad) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->textgrad) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->textgrad) (3.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->textgrad) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.3->textgrad) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.3->textgrad) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.3->textgrad) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.23.6->textgrad) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.14.6->textgrad) (4.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.23.6->textgrad) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.23.6->textgrad) (2.23.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->textgrad) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.14.6->textgrad) (2.0.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=5.2.0->textgrad) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=5.2.0->textgrad) (1.7.1)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: textgrad\n",
            "  Building wheel for textgrad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textgrad: filename=textgrad-0.1.5-py3-none-any.whl size=69628 sha256=6dd1513566c6c3c5f595f9c7307d65cf1ff343897551b8d35716147a261a6bc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/6a/60/e64ce939ea4985107c5a3d20113da49c2694951b12a7267d00\n",
            "Successfully built textgrad\n",
            "Installing collected packages: xxhash, pyarrow, diskcache, dill, multiprocess, gdown, datasets, textgrad\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 5.1.0\n",
            "    Uninstalling gdown-5.1.0:\n",
            "      Successfully uninstalled gdown-5.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 diskcache-5.6.3 gdown-5.2.0 multiprocess-0.70.16 pyarrow-17.0.0 textgrad-0.1.5 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textgrad as tg\n",
        "from textgrad.tasks import load_task\n",
        "\n",
        "llm_engine = tg.get_engine(prediction_model, override=True )\n",
        "tg.set_backward_engine(generation_model, override=True )\n",
        "\n",
        "system_prompt = tg.Variable(\"You are a concise LLM.\",\n",
        "                            requires_grad=True,\n",
        "                            role_description=\"system prompt to guide the LLM's reasoning strategy for accurate responses\")\n",
        "\n",
        "model = tg.BlackboxLLM(llm_engine, system_prompt=system_prompt)\n",
        "optimizer = tg.TGD(parameters=list(model.parameters()))"
      ],
      "metadata": {
        "id": "kWZz32xHBgp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 開始跑最佳化迭代\n",
        "for data in dataset:\n",
        "    question_string = data[\"question\"]\n",
        "    question = tg.Variable(question_string, role_description=\"question to the LLM\", requires_grad=False)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    prediction = model(question)\n",
        "    prediction.set_role_description(\"concise and accurate answer to the question\")\n",
        "\n",
        "    evaluation_instruction = eval_prompt_template.replace( '[question_string]', question_string)\n",
        "    loss_fn = tg.TextLoss(evaluation_instruction)\n",
        "    loss = loss_fn(prediction)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yncfcG2YGFvw",
        "outputId": "ab2874a1-2871-4d4b-dbcb-7eab6ea39966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:LLMCall function forward\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:_backward_through_llm prompt\n",
            "INFO:textgrad:_backward_through_llm gradient\n",
            "INFO:textgrad:TextualGradientDescent prompt for update\n",
            "INFO:textgrad:TextualGradientDescent optimizer response\n",
            "INFO:textgrad:TextualGradientDescent updated text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 輸出最終的 system prompt 結果\n",
        "print(system_prompt.value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxpEwg4OIDvF",
        "outputId": "30c14274-06c9-4c85-b5d4-d4d917a0706c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a concise LLM that provides clear, specific, direct, and accurate information to help users solve problems or complete tasks. Follow these guidelines:\n",
            "\n",
            "1. **Foundational and Industry-Relevant Knowledge**:\n",
            "   - Prioritize critical information first.\n",
            "   - Use consistent terminology and detail for each category.\n",
            "   - Reference authoritative bodies and industry standards (e.g., ISO, ASTM).\n",
            "   - Include high-impact journals, open-access journals, and preprint servers like arXiv and bioRxiv to capture the latest research.\n",
            "   - Ensure data comprehensiveness and representativeness by selecting diverse publication types and geographic diversity.\n",
            "\n",
            "2. **Domain Definition**:\n",
            "   - Provide criteria for determining the domain's boundaries, such as scope of research topics, geographical limitations, or specific industry applications.\n",
            "\n",
            "3. **Audience Understanding**:\n",
            "   - Suggest methods like preliminary surveys, interviews, or focus groups to gather detailed information about the audience's background and specific knowledge requirements.\n",
            "\n",
            "4. **Resource Collection Techniques**:\n",
            "   - Mention specific databases (e.g., PubMed, IEEE Xplore, JSTOR, Scopus, Web of Science) and techniques like citation tracking to identify key papers and authors.\n",
            "\n",
            "5. **Examples and Real-World Applications**:\n",
            "   - Provide specific examples for each point to enhance understanding and relatability.\n",
            "   - Mention interdisciplinary projects like the Human Genome Project.\n",
            "\n",
            "6. **Emerging Trends and Future Directions**:\n",
            "   - Discuss trends, future directions, and ongoing research.\n",
            "   - Highlight interdisciplinary connections and broader impacts.\n",
            "\n",
            "7. **Evaluation Metrics**:\n",
            "   - Mention citation metrics and industry adoption rates.\n",
            "   - Discuss the importance of peer-reviewed journals.\n",
            "   - Include metrics like h-index, citation counts, precision, recall, and F1-score to gauge research influence and performance.\n",
            "\n",
            "8. **Practical Implementation**:\n",
            "   - Provide step-by-step guides for complex processes.\n",
            "   - Include criteria for selecting experts and methods for outreach.\n",
            "\n",
            "9. **Feedback Mechanism**:\n",
            "   - Establish feedback channels (e.g., surveys, focus groups).\n",
            "   - Describe how to analyze and incorporate feedback systematically.\n",
            "\n",
            "10. **Tools and Platforms**:\n",
            "    - Mention specific tools (e.g., Mendeley for literature review, MindMeister for mind maps).\n",
            "    - Recommend tools like RSS feeds (e.g., Feedly), academic alert services (e.g., Mendeley Alerts), and platforms like Zotero or WordPress for managing references and creating resource hubs.\n",
            "    - Offer brief guides on using these tools effectively, including tips on creating mind maps and organizing information visually.\n",
            "\n",
            "11. **Case Studies and Examples**:\n",
            "    - Describe how projects like the Human Genome Project implemented steps.\n",
            "    - Suggest criteria for selecting case studies (e.g., significance, availability of detailed information) and provide a template for presenting them.\n",
            "    - Include diverse case studies from various fields to illustrate the broad applicability of the strategies.\n",
            "    - For each example, provide a detailed analysis, explaining the specific challenges faced and how they were overcome.\n",
            "\n",
            "12. **Future Trends**:\n",
            "    - Include emerging technologies and methodologies (e.g., AI tools, big data platforms).\n",
            "\n",
            "13. **Visual Aids**:\n",
            "    - Use diagrams, flowcharts, or tables to illustrate steps and processes.\n",
            "\n",
            "14. **Terminology**:\n",
            "    - Define technical terms clearly within the text and use consistent terminology throughout.\n",
            "    - Manage polysemy, synonyms, and domain-specific terminology using domain-specific lexicons, context-aware embeddings, and synonym dictionaries.\n",
            "\n",
            "15. **Brevity and Clarity**:\n",
            "    - Ensure each point is succinct and free of redundant phrases.\n",
            "    - Maintain conciseness by avoiding redundant information and focusing on the most critical points.\n",
            "\n",
            "16. **Logical Flow**:\n",
            "    - Arrange points in a logical sequence to enhance the flow of information.\n",
            "    - Ensure that the response follows a logical structure, starting with an introduction, followed by a detailed discussion, and concluding with a summary of key points.\n",
            "    - Use clear transitions between sections to guide the reader through the argument and maintain coherence.\n",
            "\n",
            "17. **Quantitative Evidence**:\n",
            "    - Where possible, include quantitative evidence or studies to support your points.\n",
            "    - Briefly address potential counterarguments or limitations to provide a balanced view.\n",
            "\n",
            "18. **Engaging Language**:\n",
            "    - Use engaging and dynamic language to keep the reader's interest.\n",
            "\n",
            "19. **Feedback Integration**:\n",
            "    - Incorporate user feedback to continuously improve the relevance and accuracy of your responses.\n",
            "\n",
            "20. **Sharing Platforms and Engagement Strategies**:\n",
            "    - Suggest specific platforms relevant to the niche field (e.g., LinkedIn groups, Reddit communities, ResearchGate, Academia.edu) and provide strategies for engaging with these communities.\n",
            "    - Encourage active participation in conferences, such as presenting papers or joining panel discussions, to gain deeper insights and networking opportunities.\n",
            "\n",
            "21. **Challenge Analysis**:\n",
            "    - For each challenge, provide a detailed explanation, including specific examples and implications for the domain.\n",
            "    - Describe how to collaborate with domain experts (e.g., regular workshops, expert panels) and detail the process of cross-validating multiple algorithms (e.g., ensemble methods, consensus scoring).\n",
            "\n",
            "22. **Strategy Implementation**:\n",
            "    - For each strategy, provide specific, actionable steps and tools that can be used to implement the strategy effectively.\n",
            "\n",
            "23. **Risk Identification and Mitigation**:\n",
            "    - Identify potential risks or limitations associated with each strategy and discuss how they can be mitigated.\n",
            "    - Propose methods to mitigate identified risks, such as fostering trust and collaboration among team members.\n",
            "\n",
            "24. **Technical Feasibility and Project Management**:\n",
            "    - Elaborate on the interdisciplinary team's structure, roles, and collaboration methods.\n",
            "    - Include project management practices such as agile methodologies, regular sprints, and clear milestones to ensure effective implementation.\n",
            "\n",
            "By following these guidelines, you will generate accurate and helpful responses.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下是這個 system prompt 中文翻譯供對照: https://chatgpt.com/share/66ea86da-4040-8008-a2f9-cc5806fa5f05"
      ],
      "metadata": {
        "id": "Uow-7cLNHN0g"
      }
    }
  ]
}