{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ä½¿ç”¨ DSPy æœ€ä½³åŒ– classification few-shot prompt ğŸ†\n",
        "\n",
        "\n",
        "é€™å€‹ Notebook ä½¿ç”¨ https://dspy-docs.vercel.app/ é€²è¡Œ  prompt çš„æœ€ä½³åŒ–\n",
        "\n",
        "* è¼¸å…¥ä½ çš„ä»»å‹™æè¿°ä»¥åŠåˆ†é¡é¸é …\n",
        "* å°±èƒ½ç”¢å‡ºå¾ˆå²å®³ few-shot prompt\n",
        "* ç”¨åœ¨æœ‰æ¨™æº–ç­”æ¡ˆçš„å–®é¸åˆ†é¡å ´æ™¯\n",
        "\n",
        "ä½œè€…å’Œæ¼”è¬›æŠ•å½±ç‰‡: ihower https://ihower.tw/blog/archives/12444\n",
        "\n",
        "### æµç¨‹\n",
        "\n",
        "1. ä½¿ç”¨ o1-preview åˆæˆè¨“ç·´å•é¡Œ\n",
        "2. ä½¿ç”¨ gpt-4o é€²è¡Œ DSPy æœ€ä½³åŒ–\n",
        "3. ç”¢ç”Ÿé©åˆ gpt-4o-mini çš„ few-shot prompt\n"
      ],
      "metadata": {
        "id": "IFDt4c0fmyqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. è¨­å®š OpenAI API key\n",
        "\n",
        "è«‹é» google colab å·¦é‚Šå´æ¬„çš„é‘°åŒ™ç¬¦è™Ÿï¼Œæ–°å¢å¯†é‘°ï¼Œåç¨±æ˜¯ openai_api_keyï¼Œå€¼å°±å¡« API key"
      ],
      "metadata": {
        "id": "scW_2SCnqzlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import json\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api_key')"
      ],
      "metadata": {
        "id": "tualI9vid4uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. è¨­å®šåƒæ•¸"
      ],
      "metadata": {
        "id": "2VRilB9vq3WP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_model = \"o1-preview\" # åˆæˆè¨“ç·´å•é¡Œçš„æ¨¡å‹ï¼Œè‹¥ä½ æ²’æœ‰ o1 æ¬Šé™ï¼Œè«‹æ”¹ç”¨ gpt-4o\"\n",
        "generation_model = \"gpt-4o\" # åˆæˆ prompt çš„æ¨¡å‹\n",
        "prediction_model = \"gpt-4o-mini\" # ç”¨ä¾†åŸ·è¡Œ prompt çš„æ¨¡å‹\n",
        "\n",
        "task_description = \"æƒ…æ„Ÿåˆ†æï¼Œå¾ä¸€æ®µç•™è¨€ä¸­åˆ†æå‡ºæ–‡å­—çš„èªæ°£\" # ä»»å‹™æè¿°ï¼Œè«‹ä¿®æ”¹æˆä½ çš„ä»»å‹™\n",
        "categories = ['çŸ›ç›¾', 'æ„Ÿæ…¨', 'å¿å¿‘', 'é‡‹ç„¶', 'æ•¬ç•', 'æ†æ†«', 'æ‡·èˆŠ', 'å¤±è½', 'å¿ƒé…¸', 'å›°æƒ‘'] # åˆ†é¡çš„æ¨™ç±¤ï¼Œè«‹ä¿®æ”¹\n",
        "\n",
        "questions_num = len(categories) * 10  # è¦åˆæˆå¤šå°‘è¨“ç·´è³‡æ–™ï¼Œè·ŸèŠ±è²»çš„ API æˆæœ¬æœ‰é—œ"
      ],
      "metadata": {
        "id": "uwTgSjkAhbLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. åˆæˆæœ€ä½³åŒ–éœ€è¦çš„ dataset"
      ],
      "metadata": {
        "id": "s8gGPE_veNsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_prompt = f\"\"\"You are tasked with generating question-answer pairs for a classification task.\n",
        "The questions should be based on a given task description, and the answers should be one of the provided categories. Here's what you need to do:\n",
        "\n",
        "First, review the task description:\n",
        "<task_description>\n",
        "{task_description}\n",
        "</task_description>\n",
        "\n",
        "Next, familiarize yourself with the categories for classification:\n",
        "<categories>\n",
        "{categories}\n",
        "</categories>\n",
        "\n",
        "Your goal is to create {questions_num} question-answer pairs that are relevant to the task description and can be classified into one of the given categories.\n",
        "\n",
        "Follow these guidelines when creating the QA pairs:\n",
        "\n",
        "1. Start with simple, straightforward questions and gradually increase the complexity.\n",
        "2. Ensure that the more difficult questions require multi-step reasoning or in-depth knowledge.\n",
        "3. Include a variety of question types (e.g., factual, analytical, hypothetical) relevant to the task description.\n",
        "4. Ensure that all questions are directly related to the provided task description.\n",
        "5. Make sure each question can be clearly classified into one of the given categories.\n",
        "\n",
        "Generate the QA pairs in the following JSON array format:\n",
        "\n",
        "[\n",
        "  {{ \"question\": \"Your question here\", \"answer\": \"Corresponding category\" }},\n",
        "  {{ \"question\": \"Another question\", \"answer\": \"Another category\" }},\n",
        "  ...\n",
        "]\n",
        "\n",
        "\n",
        "The returned content must be a valid JSON array containing all generated QA pairs.\n",
        "Do not add any extra text or explanations outside the JSON array. The returned content should be directly parseable as a JSON array.\n",
        "All content must be in Traditional Chinese as used in Taiwan.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "CJ-RjxgZeapV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install litellm\n",
        "\n",
        "from litellm import completion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGP1KnwoedwV",
        "outputId": "7859cd8c-e169-4919-f0cb-54a5c3e1f6c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: litellm in /usr/local/lib/python3.10/dist-packages (1.48.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm) (3.10.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.45.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (1.50.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (2.9.2)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (1.0.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm) (0.7.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm) (0.19.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.20.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.20.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->litellm) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.45.0->litellm) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->litellm) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->litellm) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->litellm) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->litellm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->litellm) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->litellm) (2024.8.30)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.7.0->litellm) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm) (4.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm) (0.24.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.45.0->litellm) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.45.0->litellm) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.45.0->litellm) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    { \"content\": synthetic_prompt, \"role\": \"user\"}\n",
        "]\n",
        "\n",
        "if not synthetic_model.startswith('o1'):\n",
        "  response = completion(model=synthetic_model, messages=messages, response_format={ \"type\": \"json_object\" })\n",
        "else:\n",
        "  # o1 ç›®å‰é‚„ä¸æ”¯æ´ json mode\n",
        "  response = completion(model=synthetic_model, messages=messages)\n",
        "\n",
        "response = response.choices[0].message.content\n",
        "dataset = json.loads(response)"
      ],
      "metadata": {
        "id": "loPGYR9oiezn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTQE32YGii61",
        "outputId": "f865defc-1915-47a2-f6ae-3188bc8eea51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WR7Kf7oHjfTq",
        "outputId": "1a9b5d61-e0a2-4b98-b531-72d4c1048e87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question': 'æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚', 'answer': 'çŸ›ç›¾'},\n",
              " {'question': 'å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚', 'answer': 'æ„Ÿæ…¨'},\n",
              " {'question': 'æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼', 'answer': 'å¿å¿‘'},\n",
              " {'question': 'äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚', 'answer': 'é‡‹ç„¶'},\n",
              " {'question': 'çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚', 'answer': 'æ•¬ç•'},\n",
              " {'question': 'çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚', 'answer': 'æ†æ†«'},\n",
              " {'question': 'æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚', 'answer': 'æ‡·èˆŠ'},\n",
              " {'question': 'æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚', 'answer': 'å¤±è½'},\n",
              " {'question': 'è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚', 'answer': 'å¿ƒé…¸'},\n",
              " {'question': 'ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚', 'answer': 'å›°æƒ‘'},\n",
              " {'question': 'é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ', 'answer': 'çŸ›ç›¾'},\n",
              " {'question': 'çœ‹è‘—èˆŠç…§ç‰‡ï¼Œä¸ç¦æ„Ÿæ…¨æ™‚é–“éå¾—çœŸå¿«ã€‚', 'answer': 'æ„Ÿæ…¨'},\n",
              " {'question': 'é¢å°æœªçŸ¥çš„å‰æ™¯ï¼Œæˆ‘å¿ƒè£¡ä¸ƒä¸Šå…«ä¸‹çš„ã€‚', 'answer': 'å¿å¿‘'},\n",
              " {'question': 'ç¶“éæ·±æ€ç†Ÿæ…®å¾Œï¼Œæˆ‘çµ‚æ–¼æ”¾ä¸‹äº†å¿ƒä¸­çš„åŸ·å¿µã€‚', 'answer': 'é‡‹ç„¶'},\n",
              " {'question': 'ç«™åœ¨é«˜å±±ä¹‹å·”ï¼Œæˆ‘æ„Ÿå—åˆ°å¤§è‡ªç„¶çš„å‰å¤§åŠ›é‡ã€‚', 'answer': 'æ•¬ç•'},\n",
              " {'question': 'çœ‹åˆ°è¡—é ­æµæµªçš„äººå€‘ï¼Œæˆ‘å¿ƒç”Ÿæ†æ†«ã€‚', 'answer': 'æ†æ†«'},\n",
              " {'question': 'é‚£æ®µæ™‚å…‰å·²é€ï¼Œä½†å›æ†¶å»æ°¸é ç•™åœ¨å¿ƒä¸­ã€‚', 'answer': 'æ‡·èˆŠ'},\n",
              " {'question': 'åŸæœ¬è¨ˆåŠƒå¥½çš„è¡Œç¨‹è¢«å–æ¶ˆäº†ï¼ŒçœŸæ˜¯å¤±è½ã€‚', 'answer': 'å¤±è½'},\n",
              " {'question': 'è½åˆ°ä»–çš„æ•…äº‹ï¼Œæˆ‘æ„Ÿåˆ°æ·±æ·±çš„å¿ƒé…¸ã€‚', 'answer': 'å¿ƒé…¸'},\n",
              " {'question': 'ä»–ç‚ºä»€éº¼è¦é›¢é–‹ï¼Ÿæˆ‘çœŸçš„ä¸æ˜ç™½ã€‚', 'answer': 'å›°æƒ‘'},\n",
              " {'question': 'é›–ç„¶ä»–å°æˆ‘å¾ˆå¥½ï¼Œä½†æˆ‘ç¸½è¦ºå¾—æˆ‘å€‘ä¹‹é–“å°‘äº†é»ä»€éº¼ã€‚', 'answer': 'çŸ›ç›¾'},\n",
              " {'question': 'æ­·ç¶“é€™éº¼å¤šé¢¨é›¨ï¼Œæˆ‘å°äººç”Ÿæœ‰äº†æ–°çš„æ„Ÿæ…¨ã€‚', 'answer': 'æ„Ÿæ…¨'},\n",
              " {'question': 'ç­‰è‘—é¢è©¦çµæœçš„é€™æ®µæ™‚é–“ï¼ŒçœŸæ˜¯è®“äººåç«‹ä¸å®‰ã€‚', 'answer': 'å¿å¿‘'},\n",
              " {'question': 'çµ‚æ–¼è§£é–‹äº†é€™å€‹è¬é¡Œï¼Œæˆ‘å…§å¿ƒç„¡æ¯”é‡‹ç„¶ã€‚', 'answer': 'é‡‹ç„¶'},\n",
              " {'question': 'åœ¨å®‡å®™é¢å‰ï¼Œäººé¡é¡¯å¾—å¦‚æ­¤æ¸ºå°ï¼Œä»¤äººå¿ƒç”Ÿæ•¬ç•ã€‚', 'answer': 'æ•¬ç•'},\n",
              " {'question': 'çœ‹åˆ°å—å‚·çš„å°é³¥ï¼Œæˆ‘ä¸ç¦æ„Ÿåˆ°æ†æ†«ã€‚', 'answer': 'æ†æ†«'},\n",
              " {'question': 'æ¯ç•¶æƒ³èµ·å­¸ç”Ÿæ™‚ä»£ï¼Œæˆ‘ç¸½æ˜¯å……æ»¿äº†æ‡·èˆŠä¹‹æƒ…ã€‚', 'answer': 'æ‡·èˆŠ'},\n",
              " {'question': 'å¤±å»äº†ä»–ï¼Œæˆ‘æ„Ÿåˆ°ç©ºè™›å’Œå¤±è½ã€‚', 'answer': 'å¤±è½'},\n",
              " {'question': 'ä»–é»˜é»˜æ‰¿å—è‘—ä¸€åˆ‡ï¼Œè®“äººè¦ºå¾—å¾ˆå¿ƒé…¸ã€‚', 'answer': 'å¿ƒé…¸'},\n",
              " {'question': 'ç‚ºä»€éº¼åŠªåŠ›äº†é‚„æ˜¯æ²’æœ‰çµæœï¼Ÿæˆ‘æ„Ÿåˆ°éå¸¸å›°æƒ‘ã€‚', 'answer': 'å›°æƒ‘'},\n",
              " {'question': 'æˆ‘åŒæ™‚æ”¶åˆ°äº†å…©å€‹å·¥ä½œé‚€ç´„ï¼Œä¸çŸ¥é“è©²é¸å“ªä¸€å€‹æ›´å¥½ã€‚', 'answer': 'çŸ›ç›¾'},\n",
              " {'question': 'ç¶“æ­·äº†é€™éº¼å¤šï¼Œæˆ‘æ·±æ·±æ„Ÿæ…¨ç”Ÿå‘½çš„ç„¡å¸¸ã€‚', 'answer': 'æ„Ÿæ…¨'},\n",
              " {'question': 'å³å°‡è¸ä¸ŠæœªçŸ¥çš„æ—…ç¨‹ï¼Œå¿ƒä¸­é›£å…å¿å¿‘ä¸å®‰ã€‚', 'answer': 'å¿å¿‘'},\n",
              " {'question': 'æŠŠéå»çš„äº‹æƒ…éƒ½æ”¾ä¸‹ï¼Œæˆ‘æ„Ÿè¦ºæ•´å€‹äººéƒ½è¼•é¬†äº†ã€‚', 'answer': 'é‡‹ç„¶'},\n",
              " {'question': 'ç•¶æˆ‘å‡è¦–æ˜Ÿç©ºæ™‚ï¼Œå…§å¿ƒå……æ»¿äº†æ•¬ç•ä¹‹æƒ…ã€‚', 'answer': 'æ•¬ç•'},\n",
              " {'question': 'çœ‹åˆ°é‚£äº›å—ç½çš„å­©å­å€‘ï¼Œæˆ‘çš„å¿ƒå……æ»¿äº†æ†æ†«ã€‚', 'answer': 'æ†æ†«'},\n",
              " {'question': 'é€™é¦–è€æ­Œå‹¾èµ·äº†æˆ‘ç„¡é™çš„æ‡·èˆŠä¹‹æƒ…ã€‚', 'answer': 'æ‡·èˆŠ'},\n",
              " {'question': 'è¨ˆç•«è¢«æ‰“äº‚äº†ï¼Œæˆ‘æ„Ÿåˆ°æ·±æ·±çš„å¤±è½ã€‚', 'answer': 'å¤±è½'},\n",
              " {'question': 'ä»–ç‚ºäº†å®¶äººé»˜é»˜ä»˜å‡ºï¼Œè®“äººå¿ƒé…¸ã€‚', 'answer': 'å¿ƒé…¸'},\n",
              " {'question': 'é¢å°è¤‡é›œçš„å±€å‹¢ï¼Œæˆ‘æ„Ÿåˆ°ç„¡æ¯”å›°æƒ‘ã€‚', 'answer': 'å›°æƒ‘'},\n",
              " {'question': 'ä»–èªªçš„æ¯å¥è©±éƒ½è®“æˆ‘æ„Ÿåˆ°å…§å¿ƒçŸ›ç›¾é‡é‡ã€‚', 'answer': 'çŸ›ç›¾'},\n",
              " {'question': 'çœ‹è‘—å­©å­å€‘çš„æˆé•·ï¼Œä¸ç¦æ„Ÿæ…¨æ™‚é–“çš„é£›é€ã€‚', 'answer': 'æ„Ÿæ…¨'},\n",
              " {'question': 'ä¸ç¢ºå®šæœªä¾†æœƒå¦‚ä½•ï¼Œå¿ƒè£¡ç¸½æ˜¯å¿å¿‘ä¸å®‰ã€‚', 'answer': 'å¿å¿‘'},\n",
              " {'question': 'çµ‚æ–¼é”æˆäº†ç›®æ¨™ï¼Œæˆ‘æ„Ÿåˆ°ç„¡æ¯”é‡‹ç„¶ã€‚', 'answer': 'é‡‹ç„¶'},\n",
              " {'question': 'é€²å…¥å¤è€çš„å¯ºå»Ÿï¼Œè®“äººå¿ƒç”Ÿæ•¬ç•ã€‚', 'answer': 'æ•¬ç•'},\n",
              " {'question': 'çœ‹åˆ°å­¤ç¨çš„è€äººï¼Œæˆ‘æ„Ÿåˆ°ä¸€çµ²æ†æ†«ã€‚', 'answer': 'æ†æ†«'},\n",
              " {'question': 'æ¯æ¬¡å›åˆ°æ•…é„‰ï¼Œç¸½æ˜¯è®“æˆ‘æ‡·èˆŠä¸å·²ã€‚', 'answer': 'æ‡·èˆŠ'},\n",
              " {'question': 'åŠªåŠ›äº†é€™éº¼ä¹…å»æ²’æœ‰çµæœï¼ŒçœŸçš„å¾ˆå¤±è½ã€‚', 'answer': 'å¤±è½'},\n",
              " {'question': 'çœ‹è‘—ä»–ç¨è‡ªæ‰¿å—ä¸€åˆ‡ï¼Œå¿ƒè£¡æ„Ÿåˆ°å¾ˆå¿ƒé…¸ã€‚', 'answer': 'å¿ƒé…¸'},\n",
              " {'question': 'ç‚ºä»€éº¼ä»–æœƒé€™æ¨£å°æˆ‘ï¼Œæˆ‘æ„Ÿåˆ°éå¸¸å›°æƒ‘ã€‚', 'answer': 'å›°æƒ‘'}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ä½¿ç”¨ DSPy æœ€ä½³åŒ– few-shot prompt"
      ],
      "metadata": {
        "id": "sba5oxcreL48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dspy-ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c96DsRFcigxd",
        "outputId": "d2a7a18c-b1e2-49c8-9de3-a9a34fa67692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dspy-ai\n",
            "  Downloading dspy_ai-2.5.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/40.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from dspy-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting datasets (from dspy-ai)\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (1.4.2)\n",
            "Requirement already satisfied: litellm in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (1.48.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (1.50.0)\n",
            "Collecting optuna (from dspy-ai)\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (2.1.4)\n",
            "Requirement already satisfied: pydantic~=2.0 in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (2.9.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (2.32.3)\n",
            "Collecting structlog (from dspy-ai)\n",
            "  Downloading structlog-24.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (4.66.5)\n",
            "Collecting ujson (from dspy-ai)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (0.27.2)\n",
            "Collecting magicattr~=0.1.6 (from dspy-ai)\n",
            "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting diskcache (from dspy-ai)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.0->dspy-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.0->dspy-ai) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.0->dspy-ai) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->dspy-ai) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy-ai) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets->dspy-ai)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->dspy-ai)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets->dspy-ai)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets->dspy-ai)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->dspy-ai) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->dspy-ai) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy-ai) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->dspy-ai) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->dspy-ai) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (2024.8.30)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->dspy-ai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->dspy-ai) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->dspy-ai) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm->dspy-ai) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm->dspy-ai) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm->dspy-ai) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm->dspy-ai) (4.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from litellm->dspy-ai) (1.0.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm->dspy-ai) (0.7.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm->dspy-ai) (0.19.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->dspy-ai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai->dspy-ai) (0.5.0)\n",
            "Collecting alembic>=1.5.0 (from optuna->dspy-ai)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna->dspy-ai)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->dspy-ai) (2.0.35)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy-ai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy-ai) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy-ai) (2024.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->dspy-ai)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->dspy-ai) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->dspy-ai) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->dspy-ai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->dspy-ai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->dspy-ai) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->dspy-ai) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->dspy-ai) (4.0.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm->dspy-ai) (3.20.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm->dspy-ai) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm->dspy-ai) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm->dspy-ai) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm->dspy-ai) (0.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dspy-ai) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->dspy-ai) (3.1.1)\n",
            "Downloading dspy_ai-2.5.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.7/298.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading structlog-24.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: magicattr, xxhash, ujson, structlog, pyarrow, Mako, diskcache, dill, colorlog, backoff, multiprocess, alembic, optuna, datasets, dspy-ai\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.3 backoff-2.2.1 colorlog-6.8.2 datasets-3.0.1 dill-0.3.8 diskcache-5.6.3 dspy-ai-2.5.0 magicattr-0.1.6 multiprocess-0.70.16 optuna-4.0.0 pyarrow-17.0.0 structlog-24.4.0 ujson-5.10.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYrOwuiKdoKZ"
      },
      "outputs": [],
      "source": [
        "import dspy\n",
        "from dspy.teleprompt import MIPROv2\n",
        "from dspy.evaluate import answer_exact_match\n",
        "\n",
        "prompt_llm = dspy.OpenAI(\n",
        "    model=generation_model,\n",
        "    api_key=os.environ['OPENAI_API_KEY']\n",
        ")\n",
        "\n",
        "task_llm = dspy.OpenAI(\n",
        "    model=prediction_model,\n",
        "    api_key=os.environ['OPENAI_API_KEY']\n",
        ")\n",
        "\n",
        "dspy.settings.configure(lm=task_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¦‚æœä½ ç”¨ gpt-4o è·‘ï¼Œdataset æ ¼å¼å¯èƒ½æœƒè·Ÿæˆ‘ç”¨ o1-preview è·‘å‡ºä¾†ä¸ä¸€æ¨£ï¼Œä»¥ä¸‹è¦è‡ªå·±æ›´æ­£ä¸€ä¸‹:"
      ],
      "metadata": {
        "id": "NL6m-6WlHyte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_examples = [\n",
        "    dspy.Example({'question': q[\"question\"], 'answer': q[\"answer\"]}) for q in dataset\n",
        "]\n",
        "\n",
        "trainset = [x.with_inputs('question') for x in few_shot_examples]"
      ],
      "metadata": {
        "id": "4GEEuvZ9d880"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DSPy çš„ code: å®šç¾© prompt çš„çµæ§‹"
      ],
      "metadata": {
        "id": "8Cizis2kEhkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionLabel(dspy.Signature):\n",
        "    question = dspy.InputField(desc=\"The input question to be categorized\")\n",
        "    answer = dspy.OutputField(desc=\"The assigned category or label for the question\")\n",
        "\n",
        "class QuestionClassification(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.classifier = dspy.Predict(QuestionLabel)\n",
        "\n",
        "    def forward(self, question: str):\n",
        "        return self.classifier(question=question)"
      ],
      "metadata": {
        "id": "zZujsc9YkUHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MIProv2 å„ªåŒ–å™¨çš„æ–‡ä»¶: https://dspy-docs.vercel.app/docs/deep-dive/optimizers/miprov2\n",
        "\n",
        "è©•ä¼°æ¡ç”¨å…§å»ºçš„ answer_exact_match æ–¹æ³•ï¼Œæœ‰æ¨™æº–ç­”æ¡ˆï¼Œå°±æª¢æŸ¥æ˜¯å¦ä¸€æ¨¡ä¸€æ¨£å³å¯"
      ],
      "metadata": {
        "id": "E0JN2QEAoP4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teleprompter = MIPROv2(prompt_model=prompt_llm, task_model=task_llm, metric=answer_exact_match, num_candidates=10, init_temperature=1, verbose=True)\n",
        "\n",
        "# é–‹å§‹è·‘æœ€ä½³åŒ–è¿­ä»£\n",
        "compiled_program = teleprompter.compile(QuestionClassification(), trainset=trainset, requires_permission_to_run=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6SVLmgdoTJh",
        "outputId": "4e753981-75c9-43a2-d60b-842ac9011113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning MIPROv2 optimization process...\n",
            "\n",
            "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
            "These will be used for as few-shot examples candidates for our program and for creating instructions.\n",
            "\n",
            "Bootstrapping N=10 sets of demonstrations...\n",
            "Bootstrapping set 1/10\n",
            "Bootstrapping set 2/10\n",
            "Bootstrapping set 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:03<00:01,  2.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 4 full traces after 8 examples in round 0.\n",
            "Bootstrapping set 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:03<00:01,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 4 full traces after 8 examples in round 0.\n",
            "Bootstrapping set 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|â–ˆâ–ˆ        | 2/10 [00:01<00:04,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 2 full traces after 3 examples in round 0.\n",
            "Bootstrapping set 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|â–ˆ         | 1/10 [00:00<00:04,  1.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 2 examples in round 0.\n",
            "Bootstrapping set 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:01<00:03,  2.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 2 full traces after 4 examples in round 0.\n",
            "Bootstrapping set 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|â–ˆâ–ˆ        | 2/10 [00:00<00:03,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 2 full traces after 3 examples in round 0.\n",
            "Bootstrapping set 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:02<00:02,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 3 full traces after 6 examples in round 0.\n",
            "Bootstrapping set 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|â–ˆ         | 1/10 [00:00<00:05,  1.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrapped 1 full traces after 2 examples in round 0.\n",
            "\n",
            "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
            "In this step, by default we will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
            "SOURCE CODE: QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.classifier(question=question)\n",
            "\n",
            "DATA SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "Proposing instructions...\n",
            "\n",
            "Using a randomly generated configuration for our grounded proposer.\n",
            "Selected tip: creative\n",
            "PROGRAM DESCRIPTION: ```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "task_demos \n",
            "\n",
            "\n",
            "\n",
            "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "DATASET SUMMARY: A description of the dataset that we are using.\n",
            "\n",
            "PROGRAM CODE: Language model program designed to solve a particular task.\n",
            "\n",
            "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
            "\n",
            "MODULE: The module to create an instruction for.\n",
            "\n",
            "TASK DEMO(S): Example inputs/outputs of our module.\n",
            "\n",
            "BASIC INSTRUCTION: Basic instruction.\n",
            "\n",
            "TIP: A suggestion for how to go about generating the new instruction.\n",
            "\n",
            "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
            "\n",
            "---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM CODE:\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.classifier(question=question)\n",
            "\n",
            "\n",
            "PROGRAM DESCRIPTION: ```python QuestionLabel(question -> answer instructions='Given the fields `question`, produce the fields `answer`.' question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'}) answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'}) ) class QuestionClassification(dspy.Module): def __init__(self): super().__init__() self.classifier = dspy.Predict(QuestionLabel) def forward(self, question: str):\n",
            "\n",
            "MODULE: Predict(question) -> answer\n",
            "\n",
            "TASK DEMO(S): \n",
            "\n",
            "BASIC INSTRUCTION: Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "TIP: Don't be afraid to be creative when creating the new instruction!\n",
            "\n",
            "PROPOSED INSTRUCTION:\u001b[32m ---\n",
            "\n",
            "DATASET SUMMARY: Observations: \n",
            "1. **Topic and Content**: \n",
            "   - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. \n",
            "   - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: \n",
            "   - Each input example is a **sentence** written in **Mandarin Chinese**. \n",
            "   - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: \n",
            "   - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence.\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED INSTRUCTION: Observations: \n",
            "1. **Topic and Content**: \n",
            "   - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. \n",
            "   - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: \n",
            "   - Each input example is a **sentence** written in **Mandarin Chinese**. \n",
            "   - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: \n",
            "   - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence.\n",
            "Using a randomly generated configuration for our grounded proposer.\n",
            "Selected tip: description\n",
            "PROGRAM DESCRIPTION: ```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "task_demos \n",
            "\n",
            "\n",
            "\n",
            "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "DATASET SUMMARY: A description of the dataset that we are using.\n",
            "\n",
            "PROGRAM CODE: Language model program designed to solve a particular task.\n",
            "\n",
            "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
            "\n",
            "MODULE: The module to create an instruction for.\n",
            "\n",
            "TASK DEMO(S): Example inputs/outputs of our module.\n",
            "\n",
            "BASIC INSTRUCTION: Basic instruction.\n",
            "\n",
            "TIP: A suggestion for how to go about generating the new instruction.\n",
            "\n",
            "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
            "\n",
            "---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM CODE:\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.classifier(question=question)\n",
            "\n",
            "\n",
            "PROGRAM DESCRIPTION: ```python QuestionLabel(question -> answer instructions='Given the fields `question`, produce the fields `answer`.' question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'}) answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'}) ) class QuestionClassification(dspy.Module): def __init__(self): super().__init__() self.classifier = dspy.Predict(QuestionLabel) def forward(self, question: str):\n",
            "\n",
            "MODULE: Predict(question) -> answer\n",
            "\n",
            "TASK DEMO(S): \n",
            "\n",
            "BASIC INSTRUCTION: Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "TIP: Make sure your instruction is very informative and descriptive.\n",
            "\n",
            "PROPOSED INSTRUCTION:\u001b[32m DATASET SUMMARY: The dataset consists of Mandarin Chinese sentences, each describing a scenario or context that evokes a specific emotional response. The aim is to associate each scenario with a corresponding emotional state. Each scenario is concise, declarative, and straightforward, while the responses are single-word labels representing the emotion.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question',\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED INSTRUCTION: The dataset consists of Mandarin Chinese sentences, each describing a scenario or context that evokes a specific emotional response. The aim is to associate each scenario with a corresponding emotional state. Each scenario is concise, declarative, and straightforward, while the responses are single-word labels representing the emotion.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question',\n",
            "Using a randomly generated configuration for our grounded proposer.\n",
            "Selected tip: high_stakes\n",
            "PROGRAM DESCRIPTION: The task this program is designed to solve is the classification of questions based on their emotional content or sentiment. Specifically, it takes an input question and assigns an emotional category or label to it.\n",
            "\n",
            "Here's how it works:\n",
            "1. **QuestionLabel Class Definition**: This class contains the structure for processing the question and generating an answer. It uses a field `question` to accept the input question and a field `answer` to produce the labeled category.\n",
            "2. **QuestionClassification Module**: This module initializes a classifier using the `QuestionLabel` class and includes a `forward` method which accepts a question as input and returns its classified category.\n",
            "3. **Language Model Prediction**: The `self.classifier` uses a\n",
            "task_demos Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "DATASET SUMMARY: A description of the dataset that we are using.\n",
            "\n",
            "PROGRAM CODE: Language model program designed to solve a particular task.\n",
            "\n",
            "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
            "\n",
            "MODULE: The module to create an instruction for.\n",
            "\n",
            "TASK DEMO(S): Example inputs/outputs of our module.\n",
            "\n",
            "BASIC INSTRUCTION: Basic instruction.\n",
            "\n",
            "TIP: A suggestion for how to go about generating the new instruction.\n",
            "\n",
            "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
            "\n",
            "---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM CODE:\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.classifier(question=question)\n",
            "\n",
            "\n",
            "PROGRAM DESCRIPTION: The task this program is designed to solve is the classification of questions based on their emotional content or sentiment. Specifically, it takes an input question and assigns an emotional category or label to it. Here's how it works: 1. **QuestionLabel Class Definition**: This class contains the structure for processing the question and generating an answer. It uses a field `question` to accept the input question and a field `answer` to produce the labeled category. 2. **QuestionClassification Module**: This module initializes a classifier using the `QuestionLabel` class and includes a `forward` method which accepts a question as input and returns its classified category. 3. **Language Model Prediction**: The `self.classifier` uses a\n",
            "\n",
            "MODULE: Predict(question) -> answer\n",
            "\n",
            "TASK DEMO(S):\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "\n",
            "BASIC INSTRUCTION: Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "TIP: The instruction should include a high stakes scenario in which the LM must solve the task!\n",
            "\n",
            "PROPOSED INSTRUCTION:\u001b[32m DATASET SUMMARY: Observations: \n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED INSTRUCTION: Observations: \n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "Using a randomly generated configuration for our grounded proposer.\n",
            "Selected tip: description\n",
            "PROGRAM DESCRIPTION: The program appears to be designed to solve the task of **question classification** or **text categorization** in a specific context. Specifically, it reads a given question as input and produces a corresponding category or label based on the content of the question.\n",
            "\n",
            "Here's how the program goes about solving this task:\n",
            "\n",
            "1. **Definition of Input and Output Fields**:\n",
            "   - The `QuestionLabel` function defends the input and output fields. The `question` field is marked as required and is described as \"The input question to be categorized\". \n",
            "   - The `answer` field is also required and is intended to hold the categorized label or category for the corresponding question.\n",
            "\n",
            "2. **Module Initialization**:\n",
            "   - The `\n",
            "task_demos Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "DATASET SUMMARY: A description of the dataset that we are using.\n",
            "\n",
            "PROGRAM CODE: Language model program designed to solve a particular task.\n",
            "\n",
            "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
            "\n",
            "MODULE: The module to create an instruction for.\n",
            "\n",
            "TASK DEMO(S): Example inputs/outputs of our module.\n",
            "\n",
            "BASIC INSTRUCTION: Basic instruction.\n",
            "\n",
            "TIP: A suggestion for how to go about generating the new instruction.\n",
            "\n",
            "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
            "\n",
            "---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM CODE:\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.classifier(question=question)\n",
            "\n",
            "\n",
            "PROGRAM DESCRIPTION: The program appears to be designed to solve the task of **question classification** or **text categorization** in a specific context. Specifically, it reads a given question as input and produces a corresponding category or label based on the content of the question. Here's how the program goes about solving this task: 1. **Definition of Input and Output Fields**: - The `QuestionLabel` function defends the input and output fields. The `question` field is marked as required and is described as \"The input question to be categorized\". - The `answer` field is also required and is intended to hold the categorized label or category for the corresponding question. 2. **Module Initialization**: - The `\n",
            "\n",
            "MODULE: Predict(question) -> answer\n",
            "\n",
            "TASK DEMO(S):\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "\n",
            "BASIC INSTRUCTION: Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "TIP: Make sure your instruction is very informative and descriptive.\n",
            "\n",
            "PROPOSED INSTRUCTION:\u001b[32m ---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - The dataset consists of **emotional responses**. Each input sentence provides a scenario or context leading to a specific emotion. - It is designed to map situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Input sentences are in **Mandarin Chinese**. - Sentences are simple and declarative, offering a natural context for emotion elicitation. 3. **Conciseness**: - Responses are **single words**, representing the emotion elicited by the scenario. - Sentences are concise and direct.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED INSTRUCTION: Observations: 1. **Topic and Content**: - The dataset consists of **emotional responses**. Each input sentence provides a scenario or context leading to a specific emotion. - It is designed to map situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Input sentences are in **Mandarin Chinese**. - Sentences are simple and declarative, offering a natural context for emotion elicitation. 3. **Conciseness**: - Responses are **single words**, representing the emotion elicited by the scenario. - Sentences are concise and direct.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce\n",
            "Using a randomly generated configuration for our grounded proposer.\n",
            "Selected tip: none\n",
            "PROGRAM DESCRIPTION: Pseudocode for a language model program designed to solve a particular task.\n",
            "EXAMPLE OF PROGRAM IN USE: An example of the program in use.\n",
            "SUMMARY OF PROGRAM ABOVE: Describe what task the program is designed to solve, and how it goes about solving this task.\n",
            "\n",
            "---\n",
            "\n",
            "PROGRAM CODE:\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field\n",
            "task_demos Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "DATASET SUMMARY: A description of the dataset that we are using.\n",
            "\n",
            "PROGRAM CODE: Language model program designed to solve a particular task.\n",
            "\n",
            "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
            "\n",
            "MODULE: The module to create an instruction for.\n",
            "\n",
            "TASK DEMO(S): Example inputs/outputs of our module.\n",
            "\n",
            "BASIC INSTRUCTION: Basic instruction.\n",
            "\n",
            "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
            "\n",
            "---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM CODE:\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.classifier(question=question)\n",
            "\n",
            "\n",
            "PROGRAM DESCRIPTION: Pseudocode for a language model program designed to solve a particular task. EXAMPLE OF PROGRAM IN USE: An example of the program in use. SUMMARY OF PROGRAM ABOVE: Describe what task the program is designed to solve, and how it goes about solving this task. --- PROGRAM CODE: QuestionLabel(question -> answer instructions='Given the fields `question`, produce the fields `answer`.' question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'}) answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field\n",
            "\n",
            "MODULE: Predict(question) -> answer\n",
            "\n",
            "TASK DEMO(S):\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "\n",
            "BASIC INSTRUCTION: Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "PROPOSED INSTRUCTION:\u001b[32m DATASET SUMMARY: The dataset consists of Mandarin Chinese sentences that describe situations or contexts leading to specific emotional responses. Each input sentence is simple and declarative, and the goal is to map these sentences to corresponding emotional states, reported as single-word responses.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', '\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED INSTRUCTION: The dataset consists of Mandarin Chinese sentences that describe situations or contexts leading to specific emotional responses. Each input sentence is simple and declarative, and the goal is to map these sentences to corresponding emotional states, reported as single-word responses.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', '\n",
            "Using a randomly generated configuration for our grounded proposer.\n",
            "Selected tip: high_stakes\n",
            "PROGRAM DESCRIPTION: **\n",
            "\n",
            "The task this program is designed to solve is the classification or categorization of questions. It aims to assign a specific label or category to a given input question. This can be particularly useful in tasks such as sentiment analysis, intention detection, topic categorization, or any other scenario where understanding the context or type of a question is critical.\n",
            "\n",
            "Here's how the program works:\n",
            "\n",
            "1. **QuestionLabel Definition**:\n",
            "    - This is a structured format with input and output fields defined. The input field is `question` which is a required string, described as \"The input question to be categorized\" with a prefix \"Question:\".\n",
            "    - The output field is `answer`, also a required string, described as \"The\n",
            "task_demos Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "DATASET SUMMARY: A description of the dataset that we are using.\n",
            "\n",
            "PROGRAM CODE: Language model program designed to solve a particular task.\n",
            "\n",
            "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
            "\n",
            "MODULE: The module to create an instruction for.\n",
            "\n",
            "TASK DEMO(S): Example inputs/outputs of our module.\n",
            "\n",
            "BASIC INSTRUCTION: Basic instruction.\n",
            "\n",
            "TIP: A suggestion for how to go about generating the new instruction.\n",
            "\n",
            "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
            "\n",
            "---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM CODE:\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.classifier(question=question)\n",
            "\n",
            "\n",
            "PROGRAM DESCRIPTION: ** The task this program is designed to solve is the classification or categorization of questions. It aims to assign a specific label or category to a given input question. This can be particularly useful in tasks such as sentiment analysis, intention detection, topic categorization, or any other scenario where understanding the context or type of a question is critical. Here's how the program works: 1. **QuestionLabel Definition**: - This is a structured format with input and output fields defined. The input field is `question` which is a required string, described as \"The input question to be categorized\" with a prefix \"Question:\". - The output field is `answer`, also a required string, described as \"The\n",
            "\n",
            "MODULE: Predict(question) -> answer\n",
            "\n",
            "TASK DEMO(S):\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "\n",
            "BASIC INSTRUCTION: Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "TIP: The instruction should include a high stakes scenario in which the LM must solve the task!\n",
            "\n",
            "PROPOSED INSTRUCTION:\u001b[32m DATASET SUMMARY: Observations: \n",
            "1. **Topic and Content**: All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: Each input example is a **sentence** written in **Mandarin Chinese**. The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED INSTRUCTION: Observations: \n",
            "1. **Topic and Content**: All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: Each input example is a **sentence** written in **Mandarin Chinese**. The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel\n",
            "Using a randomly generated configuration for our grounded proposer.\n",
            "Selected tip: none\n",
            "PROGRAM DESCRIPTION: ** Pseudocode for a language model program designed to solve a particular task.\n",
            "\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.P\n",
            "task_demos Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "DATASET SUMMARY: A description of the dataset that we are using.\n",
            "\n",
            "PROGRAM CODE: Language model program designed to solve a particular task.\n",
            "\n",
            "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
            "\n",
            "MODULE: The module to create an instruction for.\n",
            "\n",
            "TASK DEMO(S): Example inputs/outputs of our module.\n",
            "\n",
            "BASIC INSTRUCTION: Basic instruction.\n",
            "\n",
            "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
            "\n",
            "---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM CODE:\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.classifier(question=question)\n",
            "\n",
            "\n",
            "PROGRAM DESCRIPTION: ** Pseudocode for a language model program designed to solve a particular task. ```python QuestionLabel(question -> answer instructions='Given the fields `question`, produce the fields `answer`.' question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'}) answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'}) ) class QuestionClassification(dspy.Module): def __init__(self): super().__init__() self.classifier = dspy.P\n",
            "\n",
            "MODULE: Predict(question) -> answer\n",
            "\n",
            "TASK DEMO(S):\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "\n",
            "BASIC INSTRUCTION: Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "PROPOSED INSTRUCTION:\u001b[32m ---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED INSTRUCTION: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "Using a randomly generated configuration for our grounded proposer.\n",
            "Selected tip: description\n",
            "PROGRAM DESCRIPTION: QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.class\n",
            "task_demos Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "DATASET SUMMARY: A description of the dataset that we are using.\n",
            "\n",
            "PROGRAM CODE: Language model program designed to solve a particular task.\n",
            "\n",
            "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
            "\n",
            "MODULE: The module to create an instruction for.\n",
            "\n",
            "TASK DEMO(S): Example inputs/outputs of our module.\n",
            "\n",
            "BASIC INSTRUCTION: Basic instruction.\n",
            "\n",
            "TIP: A suggestion for how to go about generating the new instruction.\n",
            "\n",
            "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
            "\n",
            "---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM CODE:\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.classifier(question=question)\n",
            "\n",
            "\n",
            "PROGRAM DESCRIPTION: QuestionLabel(question -> answer instructions='Given the fields `question`, produce the fields `answer`.' question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'}) answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'}) ) class QuestionClassification(dspy.Module): def __init__(self): super().__init__() self.classifier = dspy.Predict(QuestionLabel) def forward(self, question: str): return self.class\n",
            "\n",
            "MODULE: Predict(question) -> answer\n",
            "\n",
            "TASK DEMO(S):\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "\n",
            "BASIC INSTRUCTION: Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "TIP: Make sure your instruction is very informative and descriptive.\n",
            "\n",
            "PROPOSED INSTRUCTION:\u001b[32m DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED INSTRUCTION: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "Using a randomly generated configuration for our grounded proposer.\n",
            "Selected tip: description\n",
            "PROGRAM DESCRIPTION: The program above is designed to perform **emotion or sentiment classification** of questions or statements. It aims to categorize or label text inputs based on their emotional or sentiment context.\n",
            "\n",
            "Here's a detailed breakdown:\n",
            "\n",
            "### Task:\n",
            "The primary task is to classify the given text (questions or statements) into predefined emotional or sentiment categories (e.g., relief, confusion, compassion).\n",
            "\n",
            "### How it Works:\n",
            "1. **Definition of `QuestionLabel`:**\n",
            "   - **Inputs:** The input is a `question` field, which is a string that represents the question or statement to be categorized.\n",
            "   - **Outputs:** The output is an `answer` field, which is a string indicating the assigned category or label for the input question or statement.\n",
            "   - **Instructions\n",
            "task_demos Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "DATASET SUMMARY: A description of the dataset that we are using.\n",
            "\n",
            "PROGRAM CODE: Language model program designed to solve a particular task.\n",
            "\n",
            "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
            "\n",
            "MODULE: The module to create an instruction for.\n",
            "\n",
            "TASK DEMO(S): Example inputs/outputs of our module.\n",
            "\n",
            "BASIC INSTRUCTION: Basic instruction.\n",
            "\n",
            "TIP: A suggestion for how to go about generating the new instruction.\n",
            "\n",
            "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
            "\n",
            "---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM CODE:\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.classifier(question=question)\n",
            "\n",
            "\n",
            "PROGRAM DESCRIPTION: The program above is designed to perform **emotion or sentiment classification** of questions or statements. It aims to categorize or label text inputs based on their emotional or sentiment context. Here's a detailed breakdown: ### Task: The primary task is to classify the given text (questions or statements) into predefined emotional or sentiment categories (e.g., relief, confusion, compassion). ### How it Works: 1. **Definition of `QuestionLabel`:** - **Inputs:** The input is a `question` field, which is a string that represents the question or statement to be categorized. - **Outputs:** The output is an `answer` field, which is a string indicating the assigned category or label for the input question or statement. - **Instructions\n",
            "\n",
            "MODULE: Predict(question) -> answer\n",
            "\n",
            "TASK DEMO(S):\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "\n",
            "BASIC INSTRUCTION: Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "TIP: Make sure your instruction is very informative and descriptive.\n",
            "\n",
            "PROPOSED INSTRUCTION:\u001b[32m Given the input `question` which is a sentence in Mandarin Chinese describing a situation, produce the corresponding `answer` which is a single word in Mandarin Chinese that represents the emotional response elicited by the situation. For example, if the input sentence describes a scenario that makes someone feel relieved, the output should be the word for \"relief\" in Mandarin. Make sure to accurately interpret the emotional context of the input sentence and provide the most appropriate emotional label.\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED INSTRUCTION: Given the input `question` which is a sentence in Mandarin Chinese describing a situation, produce the corresponding `answer` which is a single word in Mandarin Chinese that represents the emotional response elicited by the situation. For example, if the input sentence describes a scenario that makes someone feel relieved, the output should be the word for \"relief\" in Mandarin. Make sure to accurately interpret the emotional context of the input sentence and provide the most appropriate emotional label.\n",
            "Using a randomly generated configuration for our grounded proposer.\n",
            "Selected tip: none\n",
            "PROGRAM DESCRIPTION: **\n",
            "\n",
            "The task this program is designed to solve is the classification or categorization of questions. It aims to assign a specific label or category to a given input question. This can be particularly useful in tasks such as sentiment analysis, intention detection, topic categorization, or any other scenario where understanding the context or type of a question is critical.\n",
            "\n",
            "Here's how the program works:\n",
            "\n",
            "1. **QuestionLabel Definition**:\n",
            "    - This is a structured format with input and output fields defined. The input field is `question` which is a required string, described as \"The input question to be categorized\" with a prefix \"Question:\".\n",
            "    - The output field is `answer`, also a required string, described as \"The\n",
            "task_demos Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "DATASET SUMMARY: A description of the dataset that we are using.\n",
            "\n",
            "PROGRAM CODE: Language model program designed to solve a particular task.\n",
            "\n",
            "PROGRAM DESCRIPTION: Summary of the task the program is designed to solve, and how it goes about solving it.\n",
            "\n",
            "MODULE: The module to create an instruction for.\n",
            "\n",
            "TASK DEMO(S): Example inputs/outputs of our module.\n",
            "\n",
            "BASIC INSTRUCTION: Basic instruction.\n",
            "\n",
            "PROPOSED INSTRUCTION: Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
            "\n",
            "---\n",
            "\n",
            "DATASET SUMMARY: Observations: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM CODE:\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "class QuestionClassification(dspy.Module):\n",
            "    def __init__(self):\n",
            "        super().__init__()\n",
            "        self.classifier = dspy.Predict(QuestionLabel)\n",
            "\n",
            "    def forward(self, question: str):\n",
            "        return self.classifier(question=question)\n",
            "\n",
            "\n",
            "PROGRAM DESCRIPTION: ** The task this program is designed to solve is the classification or categorization of questions. It aims to assign a specific label or category to a given input question. This can be particularly useful in tasks such as sentiment analysis, intention detection, topic categorization, or any other scenario where understanding the context or type of a question is critical. Here's how the program works: 1. **QuestionLabel Definition**: - This is a structured format with input and output fields defined. The input field is `question` which is a required string, described as \"The input question to be categorized\" with a prefix \"Question:\". - The output field is `answer`, also a required string, described as \"The\n",
            "\n",
            "MODULE: Predict(question) -> answer\n",
            "\n",
            "TASK DEMO(S):\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "\n",
            "BASIC INSTRUCTION: Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "PROPOSED INSTRUCTION:\u001b[32m DATASET SUMMARY: Observations:\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "PROPOSED INSTRUCTION: Observations:\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM\n",
            "Proposed Instructions for Predictor 0:\n",
            "\n",
            "0: Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "1: The dataset consists of Mandarin Chinese sentences, each describing a scenario or context that evokes a specific emotional response. The aim is to associate each scenario with a corresponding emotional state. Each scenario is concise, declarative, and straightforward, while the responses are single-word labels representing the emotion.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question',\n",
            "\n",
            "2: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "3: 1. **Topic and Content**: - The dataset consists of **emotional responses**. Each input sentence provides a scenario or context leading to a specific emotion. - It is designed to map situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Input sentences are in **Mandarin Chinese**. - Sentences are simple and declarative, offering a natural context for emotion elicitation. 3. **Conciseness**: - Responses are **single words**, representing the emotion elicited by the scenario. - Sentences are concise and direct.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce\n",
            "\n",
            "4: The dataset consists of Mandarin Chinese sentences that describe situations or contexts leading to specific emotional responses. Each input sentence is simple and declarative, and the goal is to map these sentences to corresponding emotional states, reported as single-word responses.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', '\n",
            "\n",
            "5: 1. **Topic and Content**: All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: Each input example is a **sentence** written in **Mandarin Chinese**. The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel\n",
            "\n",
            "6: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "\n",
            "7: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "8: Given the input `question` which is a sentence in Mandarin Chinese describing a situation, produce the corresponding `answer` which is a single word in Mandarin Chinese that represents the emotional response elicited by the situation. For example, if the input sentence describes a scenario that makes someone feel relieved, the output should be the word for \"relief\" in Mandarin. Make sure to accurately interpret the emotional context of the input sentence and provide the most appropriate emotional label.\n",
            "\n",
            "9: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM\n",
            "\n",
            "\n",
            "\n",
            "Evaluating the default program...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 40  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:03<00:00, 10.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default program score: 0.0\n",
            "\n",
            "==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
            "In this step, we will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination. Bayesian Optimization will be used for this search process.\n",
            "\n",
            "== Minibatch Trial 1 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: The dataset consists of Mandarin Chinese sentences, each describing a scenario or context that evokes a specific emotional response. The aim is to associate each scenario with a corresponding emotional state. Each scenario is concise, declarative, and straightforward, while the responses are single-word labels representing the emotion.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question',\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 12 / 25  (48.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:04<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 636.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "The dataset consists of Mandarin Chinese sentences, each describing a scenario or context that evokes a specific emotional response. The aim is to associate each scenario with a corresponding emotional state. Each scenario is concise, declarative, and straightforward, while the responses are single-word labels representing the emotion.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question',\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer: å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The dataset consists of Mandarin Chinese sentences, each describing a scenario or context that evokes a specific emotional response. The aim is to associate each scenario with a corresponding emotional state. Each scenario is concise, declarative, and straightforward, while the responses are single-word labels representing the emotion.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question',\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer: å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 48.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 2'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 2 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 20 / 25  (80.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 80.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 6', 'Predictor 1: Few-Shot Set 2'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 3 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: Given the input `question` which is a sentence in Mandarin Chinese describing a situation, produce the corresponding `answer` which is a single word in Mandarin Chinese that represents the emotional response elicited by the situation. For example, if the input sentence describes a scenario that makes someone feel relieved, the output should be the word for \"relief\" in Mandarin. Make sure to accurately interpret the emotional context of the input sentence and provide the most appropriate emotional label.\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 19 / 25  (76.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  9.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 174.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Given the input `question` which is a sentence in Mandarin Chinese describing a situation, produce the corresponding `answer` which is a single word in Mandarin Chinese that represents the emotional response elicited by the situation. For example, if the input sentence describes a scenario that makes someone feel relieved, the output should be the word for \"relief\" in Mandarin. Make sure to accurately interpret the emotional context of the input sentence and provide the most appropriate emotional label.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Given the input `question` which is a sentence in Mandarin Chinese describing a situation, produce the corresponding `answer` which is a single word in Mandarin Chinese that represents the emotional response elicited by the situation. For example, if the input sentence describes a scenario that makes someone feel relieved, the output should be the word for \"relief\" in Mandarin. Make sure to accurately interpret the emotional context of the input sentence and provide the most appropriate emotional label.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 76.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 8', 'Predictor 1: Few-Shot Set 6'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 4 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: The dataset consists of Mandarin Chinese sentences that describe situations or contexts leading to specific emotional responses. Each input sentence is simple and declarative, and the goal is to map these sentences to corresponding emotional states, reported as single-word responses.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', '\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 17 / 25  (68.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  8.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "The dataset consists of Mandarin Chinese sentences that describe situations or contexts leading to specific emotional responses. Each input sentence is simple and declarative, and the goal is to map these sentences to corresponding emotional states, reported as single-word responses.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', '\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The dataset consists of Mandarin Chinese sentences that describe situations or contexts leading to specific emotional responses. Each input sentence is simple and declarative, and the goal is to map these sentences to corresponding emotional states, reported as single-word responses.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', '\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 68.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 4', 'Predictor 1: Few-Shot Set 5'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 5 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - The dataset consists of **emotional responses**. Each input sentence provides a scenario or context leading to a specific emotion. - It is designed to map situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Input sentences are in **Mandarin Chinese**. - Sentences are simple and declarative, offering a natural context for emotion elicitation. 3. **Conciseness**: - Responses are **single words**, representing the emotion elicited by the scenario. - Sentences are concise and direct.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 18 / 25  (72.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 513.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - The dataset consists of **emotional responses**. Each input sentence provides a scenario or context leading to a specific emotion. - It is designed to map situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Input sentences are in **Mandarin Chinese**. - Sentences are simple and declarative, offering a natural context for emotion elicitation. 3. **Conciseness**: - Responses are **single words**, representing the emotion elicited by the scenario. - Sentences are concise and direct.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±è½\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - The dataset consists of **emotional responses**. Each input sentence provides a scenario or context leading to a specific emotion. - It is designed to map situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Input sentences are in **Mandarin Chinese**. - Sentences are simple and declarative, offering a natural context for emotion elicitation. 3. **Conciseness**: - Responses are **single words**, representing the emotion elicited by the scenario. - Sentences are concise and direct.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±è½\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 72.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 3', 'Predictor 1: Few-Shot Set 8'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 6 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 20 / 25  (80.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  8.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 80.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 3'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 7 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 20 / 25  (80.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 685.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 80.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 9', 'Predictor 1: Few-Shot Set 5'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 8 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 20 / 25  (80.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 12.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 362.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å›°æƒ‘\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å›°æƒ‘\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 80.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 4'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 9 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: Given the fields `question`, produce the fields `answer`.\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 18 / 25  (72.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  7.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 653.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 72.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 7'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 10 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 19 / 25  (76.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 12.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 418.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point, often\n",
            "\n",
            "PROGRAM\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 76.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 9', 'Predictor 1: Few-Shot Set 7'].\n",
            "\n",
            "\n",
            "===== Full Eval 1 =====\n",
            "Doing full eval on next top averaging program (Avg Score: 80.0) so far from mini-batch trials...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 32 / 40  (80.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 28.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mBest full eval score so far!\u001b[0m Score: 80.0\n",
            "=======================\n",
            "\n",
            "\n",
            "== Minibatch Trial 11 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 20 / 25  (80.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 660.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 542.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 80.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 6', 'Predictor 1: Few-Shot Set 2'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 12 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 19 / 25  (76.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 32.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 358.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 76.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 3'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 13 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 15 / 25  (60.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 665.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±è½\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±è½\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 60.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 6', 'Predictor 1: Few-Shot Set 0'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 14 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: Each input example is a **sentence** written in **Mandarin Chinese**. The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 16 / 25  (64.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 704.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: Each input example is a **sentence** written in **Mandarin Chinese**. The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: Each input example is a **sentence** written in **Mandarin Chinese**. The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 64.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 5', 'Predictor 1: Few-Shot Set 3'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 15 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: Each input example is a **sentence** written in **Mandarin Chinese**. The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 19 / 25  (76.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:03<00:00,  7.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 759.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: Each input example is a **sentence** written in **Mandarin Chinese**. The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: Each input example is a **sentence** written in **Mandarin Chinese**. The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 76.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 5', 'Predictor 1: Few-Shot Set 9'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 16 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 19 / 25  (76.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 399.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å›°æƒ‘\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å›°æƒ‘\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 76.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 4'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 17 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 20 / 25  (80.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 80.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 2'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 18 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 17 / 25  (68.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 705.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 68.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 6', 'Predictor 1: Few-Shot Set 3'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 19 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 18 / 25  (72.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  9.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 606.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m æ²®å–ª\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m æ²®å–ª\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 72.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 6', 'Predictor 1: Few-Shot Set 9'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 20 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 22 / 25  (88.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 88.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 1'].\n",
            "\n",
            "\n",
            "===== Full Eval 2 =====\n",
            "Doing full eval on next top averaging program (Avg Score: 88.0) so far from mini-batch trials...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 33 / 40  (82.5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 31.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mBest full eval score so far!\u001b[0m Score: 82.5\n",
            "=======================\n",
            "\n",
            "\n",
            "== Minibatch Trial 21 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 21 / 25  (84.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 611.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 585.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 84.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 1'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 22 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 20 / 25  (80.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 818.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 229.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 80.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 1'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 23 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: The dataset consists of Mandarin Chinese sentences that describe situations or contexts leading to specific emotional responses. Each input sentence is simple and declarative, and the goal is to map these sentences to corresponding emotional states, reported as single-word responses.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', '\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 10 / 25  (40.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:07<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "The dataset consists of Mandarin Chinese sentences that describe situations or contexts leading to specific emotional responses. Each input sentence is simple and declarative, and the goal is to map these sentences to corresponding emotional states, reported as single-word responses.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', '\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The dataset consists of Mandarin Chinese sentences that describe situations or contexts leading to specific emotional responses. Each input sentence is simple and declarative, and the goal is to map these sentences to corresponding emotional states, reported as single-word responses.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', '\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 40.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 4', 'Predictor 1: Few-Shot Set 1'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 24 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 22 / 25  (88.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 564.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 729.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 88.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 2', 'Predictor 1: Few-Shot Set 1'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 25 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: The dataset consists of Mandarin Chinese sentences, each describing a scenario or context that evokes a specific emotional response. The aim is to associate each scenario with a corresponding emotional state. Each scenario is concise, declarative, and straightforward, while the responses are single-word labels representing the emotion.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question',\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 10 / 25  (40.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:06<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 289.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "The dataset consists of Mandarin Chinese sentences, each describing a scenario or context that evokes a specific emotional response. The aim is to associate each scenario with a corresponding emotional state. Each scenario is concise, declarative, and straightforward, while the responses are single-word labels representing the emotion.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question',\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The dataset consists of Mandarin Chinese sentences, each describing a scenario or context that evokes a specific emotional response. The aim is to associate each scenario with a corresponding emotional state. Each scenario is concise, declarative, and straightforward, while the responses are single-word labels representing the emotion.\n",
            "\n",
            "PROGRAM CODE:\n",
            "```python\n",
            "QuestionLabel(question -> answer\n",
            "    instructions='Given the fields `question`, produce the fields `answer`.'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question',\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 40.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 1', 'Predictor 1: Few-Shot Set 1'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 26 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: Given the input `question` which is a sentence in Mandarin Chinese describing a situation, produce the corresponding `answer` which is a single word in Mandarin Chinese that represents the emotional response elicited by the situation. For example, if the input sentence describes a scenario that makes someone feel relieved, the output should be the word for \"relief\" in Mandarin. Make sure to accurately interpret the emotional context of the input sentence and provide the most appropriate emotional label.\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 21 / 25  (84.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  9.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Given the input `question` which is a sentence in Mandarin Chinese describing a situation, produce the corresponding `answer` which is a single word in Mandarin Chinese that represents the emotional response elicited by the situation. For example, if the input sentence describes a scenario that makes someone feel relieved, the output should be the word for \"relief\" in Mandarin. Make sure to accurately interpret the emotional context of the input sentence and provide the most appropriate emotional label.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Given the input `question` which is a sentence in Mandarin Chinese describing a situation, produce the corresponding `answer` which is a single word in Mandarin Chinese that represents the emotional response elicited by the situation. For example, if the input sentence describes a scenario that makes someone feel relieved, the output should be the word for \"relief\" in Mandarin. Make sure to accurately interpret the emotional context of the input sentence and provide the most appropriate emotional label.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 84.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 8', 'Predictor 1: Few-Shot Set 1'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 27 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 22 / 25  (88.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 542.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 88.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 1'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 28 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 19 / 25  (76.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 12.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 507.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 76.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 6'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 29 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: 1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 21 / 25  (84.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:01<00:00, 23.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 624.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**. 2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion. 3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 84.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 7', 'Predictor 1: Few-Shot Set 1'].\n",
            "\n",
            "\n",
            "== Minibatch Trial 30 / 30 ==\n",
            "Evaluating the following candidate program...\n",
            "\n",
            "Predictor 0\n",
            "i: Given the fields `question`, produce the fields `answer`.\n",
            "p: Answer:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 23 / 25  (92.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00, 11.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full trace of prompts in use on an example...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 0 / 1  (0.0): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Given the fields `question`, produce the fields `answer`.\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: é›–ç„¶åŠªåŠ›äº†é€™éº¼ä¹…ï¼Œä½†çµæœå»ä¸ç›¡å¦‚äººæ„ï¼Œæˆ‘è©²æ€éº¼è¾¦ï¼Ÿ\n",
            "Answer:\u001b[32m å¤±æœ›\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Score: 92.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 1'].\n",
            "\n",
            "\n",
            "===== Full Eval 3 =====\n",
            "Doing full eval on next top averaging program (Avg Score: 92.0) so far from mini-batch trials...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Average Metric: 31 / 40  (77.5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 29.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full eval score: 77.5\n",
            "Best full eval score so far: 82.5\n",
            "=======================\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. æœ€å¾Œçµæœ"
      ],
      "metadata": {
        "id": "6aFQLcUck_rd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DSPy ä¸åªæ˜¯æœ€ä½³åŒ–å·¥å…·ï¼Œæœ¬èº«å°±æ˜¯ä¸€å€‹åŸ·è¡Œæ¡†æ¶"
      ],
      "metadata": {
        "id": "3iCpeEYYsHCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_program('ç­é•·æœ‰ä»€éº¼äº†ä¸èµ·ï¼Œæˆ‘å°å­¸ä¹Ÿç•¶éç­é•·å•Š!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fhqe3OEk5lg",
        "outputId": "3e359e34-dbae-4928-dd01-bb4fc2f17e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(\n",
              "    answer='å«‰å¦’'\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¯ä»¥æŠŠæœ€ä½³åŒ–åƒæ•¸å­˜ä¸‹ä¾†ï¼Œä¸‹æ¬¡è¼‰å…¥ä½¿ç”¨"
      ],
      "metadata": {
        "id": "uwrrFvpgu6Vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_program.save(\"compiled_program.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0f0-hSluzNS",
        "outputId": "94772733-cee0-41df-d75e-50a7b7ddc260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('classifier', Predict(StringSignature(question -> answer\n",
            "    instructions='1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\\n2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\\n3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\\n\\nPROGRAM CODE'\n",
            "    question = Field(annotation=str required=True json_schema_extra={'desc': 'The input question to be categorized', '__dspy_field_type': 'input', 'prefix': 'Question:'})\n",
            "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'The assigned category or label for the question', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
            ")))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "è§€å¯Ÿæœ€å¾Œçš„æœ€ä½³åŒ– prompt:"
      ],
      "metadata": {
        "id": "DkQ9r1YssOfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print( task_llm.inspect_history(1) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ2v1F-xlCuj",
        "outputId": "98567049-3a3a-4430-b831-a8e1a3420425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç­é•·æœ‰ä»€éº¼äº†ä¸èµ·ï¼Œæˆ‘å°å­¸ä¹Ÿç•¶éç­é•·å•Š!\n",
            "Answer:\u001b[32m å«‰å¦’\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1. **Topic and Content**: - All examples revolve around **emotional responses**. Each input sentence contains a scenario or context that leads to a specific emotion. - The dataset seems aimed at mapping situations or descriptions to corresponding **emotional states**.\n",
            "2. **Syntax**: - Each input example is a **sentence** written in **Mandarin Chinese**. - The structure of the sentences is fairly simple and primarily declarative, providing a natural context for the emotion.\n",
            "3. **Conciseness**: - The responses (answers) are **single words**, representing the emotion elicited by the situation described in the sentence. - The sentences themselves are concise and to the point.\n",
            "\n",
            "PROGRAM CODE\n",
            "\n",
            "---\n",
            "\n",
            "Follow the following format.\n",
            "\n",
            "Question: The input question to be categorized\n",
            "Answer: The assigned category or label for the question\n",
            "\n",
            "---\n",
            "\n",
            "Question: å›æƒ³èµ·å°æ™‚å€™çš„æ—¥å­ï¼ŒçœŸçš„è®“äººæ„Ÿæ…¨è¬åƒã€‚\n",
            "Answer: æ„Ÿæ…¨\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘çš„ç”³è«‹è¢«æ‹’çµ•äº†ï¼Œæ„Ÿè¦ºå¾ˆå¤±è½ã€‚\n",
            "Answer: å¤±è½\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç‚ºä»€éº¼äº‹æƒ…æœƒè®Šæˆé€™æ¨£ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆå›°æƒ‘ã€‚\n",
            "Answer: å›°æƒ‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: äº‹æƒ…çµ‚æ–¼è§£æ±ºäº†ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆé‡‹ç„¶ã€‚\n",
            "Answer: é‡‹ç„¶\n",
            "\n",
            "---\n",
            "\n",
            "Question: æˆ‘ä¸çŸ¥é“è©²é¸æ“‡å“ªå€‹ï¼Œå¥½åƒæ¯å€‹é¸é …éƒ½æœ‰å¸å¼•æˆ‘çš„åœ°æ–¹ã€‚\n",
            "Answer: çŸ›ç›¾\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ˜å¤©å°±è¦è€ƒè©¦äº†ï¼Œæˆ‘å¥½ç·Šå¼µå•Šï¼\n",
            "Answer: å¿å¿‘\n",
            "\n",
            "---\n",
            "\n",
            "Question: æ¯ç•¶è½åˆ°é€™é¦–æ­Œï¼Œæˆ‘å°±æƒ³èµ·éå»çš„ç¾å¥½æ™‚å…‰ã€‚\n",
            "Answer: æ‡·èˆŠ\n",
            "\n",
            "---\n",
            "\n",
            "Question: è½åˆ°é€™å€‹æ¶ˆæ¯ï¼Œæˆ‘çš„å¿ƒè£¡é…¸é…¸çš„ã€‚\n",
            "Answer: å¿ƒé…¸\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°æµæµªçš„å°ç‹—ï¼Œæˆ‘æ„Ÿåˆ°å¾ˆæ†æ†«ã€‚\n",
            "Answer: æ†æ†«\n",
            "\n",
            "---\n",
            "\n",
            "Question: çœ‹åˆ°å£¯éº—çš„å±±æ²³ï¼Œæˆ‘å°å¤§è‡ªç„¶å……æ»¿äº†æ•¬ç•ã€‚\n",
            "Answer: æ•¬ç•\n",
            "\n",
            "---\n",
            "\n",
            "Question: ç­é•·æœ‰ä»€éº¼äº†ä¸èµ·ï¼Œæˆ‘å°å­¸ä¹Ÿç•¶éç­é•·å•Š!\n",
            "Answer:\u001b[32m å«‰å¦’\u001b[0m\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oHTZlNho2Tmr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}