# -*- coding: utf-8 -*-
"""dspy-few-shot-classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vlMSWDlic41ou-9rHLdrU15WXKYA-SQu

## ä½¿ç”¨ DSPy æœ€ä½³åŒ– classification few-shot prompt ğŸ†


é€™å€‹ Notebook ä½¿ç”¨ https://dspy-docs.vercel.app/ é€²è¡Œ  prompt çš„æœ€ä½³åŒ–

* è¼¸å…¥ä½ çš„ä»»å‹™æè¿°ä»¥åŠåˆ†é¡é¸é …
* å°±èƒ½ç”¢å‡ºå¾ˆå²å®³ few-shot prompt
* ç”¨åœ¨æœ‰æ¨™æº–ç­”æ¡ˆçš„å–®é¸åˆ†é¡å ´æ™¯

ä½œè€…å’Œæ¼”è¬›æŠ•å½±ç‰‡: ihower https://ihower.tw/blog/archives/12444

### æµç¨‹

1. ä½¿ç”¨ o1-preview åˆæˆè¨“ç·´å•é¡Œ
2. ä½¿ç”¨ gpt-4o é€²è¡Œ DSPy æœ€ä½³åŒ–
3. ç”¢ç”Ÿé©åˆ gpt-4o-mini çš„ few-shot prompt

## 0. è¨­å®š OpenAI API key

è«‹é» google colab å·¦é‚Šå´æ¬„çš„é‘°åŒ™ç¬¦è™Ÿï¼Œæ–°å¢å¯†é‘°ï¼Œåç¨±æ˜¯ openai_api_keyï¼Œå€¼å°±å¡« API key
"""

from google.colab import userdata
import json
import os

os.environ["OPENAI_API_KEY"] = userdata.get('openai_api_key')

"""## 1. è¨­å®šåƒæ•¸"""

synthetic_model = "o1-preview" # åˆæˆè¨“ç·´å•é¡Œçš„æ¨¡å‹ï¼Œè‹¥ä½ æ²’æœ‰ o1 æ¬Šé™ï¼Œè«‹æ”¹ç”¨ gpt-4o"
generation_model = "gpt-4o" # åˆæˆ prompt çš„æ¨¡å‹
prediction_model = "gpt-4o-mini" # ç”¨ä¾†åŸ·è¡Œ prompt çš„æ¨¡å‹

task_description = "æƒ…æ„Ÿåˆ†æï¼Œå¾ä¸€æ®µç•™è¨€ä¸­åˆ†æå‡ºæ–‡å­—çš„èªæ°£" # ä»»å‹™æè¿°ï¼Œè«‹ä¿®æ”¹æˆä½ çš„ä»»å‹™
categories = ['çŸ›ç›¾', 'æ„Ÿæ…¨', 'å¿å¿‘', 'é‡‹ç„¶', 'æ•¬ç•', 'æ†æ†«', 'æ‡·èˆŠ', 'å¤±è½', 'å¿ƒé…¸', 'å›°æƒ‘'] # åˆ†é¡çš„æ¨™ç±¤ï¼Œè«‹ä¿®æ”¹

questions_num = len(categories) * 10  # è¦åˆæˆå¤šå°‘è¨“ç·´è³‡æ–™ï¼Œè·ŸèŠ±è²»çš„ API æˆæœ¬æœ‰é—œ

"""## 2. åˆæˆæœ€ä½³åŒ–éœ€è¦çš„ dataset"""

synthetic_prompt = f"""You are tasked with generating question-answer pairs for a classification task.
The questions should be based on a given task description, and the answers should be one of the provided categories. Here's what you need to do:

First, review the task description:
<task_description>
{task_description}
</task_description>

Next, familiarize yourself with the categories for classification:
<categories>
{categories}
</categories>

Your goal is to create {questions_num} question-answer pairs that are relevant to the task description and can be classified into one of the given categories.

Follow these guidelines when creating the QA pairs:

1. Start with simple, straightforward questions and gradually increase the complexity.
2. Ensure that the more difficult questions require multi-step reasoning or in-depth knowledge.
3. Include a variety of question types (e.g., factual, analytical, hypothetical) relevant to the task description.
4. Ensure that all questions are directly related to the provided task description.
5. Make sure each question can be clearly classified into one of the given categories.

Generate the QA pairs in the following JSON array format:

[
  {{ "question": "Your question here", "answer": "Corresponding category" }},
  {{ "question": "Another question", "answer": "Another category" }},
  ...
]


The returned content must be a valid JSON array containing all generated QA pairs.
Do not add any extra text or explanations outside the JSON array. The returned content should be directly parseable as a JSON array.
All content must be in Traditional Chinese as used in Taiwan.
"""

!pip install litellm

from litellm import completion

messages = [
    { "content": synthetic_prompt, "role": "user"}
]

if not synthetic_model.startswith('o1'):
  response = completion(model=synthetic_model, messages=messages, response_format={ "type": "json_object" })
else:
  # o1 ç›®å‰é‚„ä¸æ”¯æ´ json mode
  response = completion(model=synthetic_model, messages=messages)

response = response.choices[0].message.content
dataset = json.loads(response)

len(dataset)

dataset

"""## 3. ä½¿ç”¨ DSPy æœ€ä½³åŒ– few-shot prompt"""

!pip install dspy-ai

import dspy
from dspy.teleprompt import MIPROv2
from dspy.evaluate import answer_exact_match

prompt_llm = dspy.OpenAI(
    model=generation_model,
    api_key=os.environ['OPENAI_API_KEY']
)

task_llm = dspy.OpenAI(
    model=prediction_model,
    api_key=os.environ['OPENAI_API_KEY']
)

dspy.settings.configure(lm=task_llm)

"""å¦‚æœä½ ç”¨ gpt-4o è·‘ï¼Œdataset æ ¼å¼å¯èƒ½æœƒè·Ÿæˆ‘ç”¨ o1-preview è·‘å‡ºä¾†ä¸ä¸€æ¨£ï¼Œä»¥ä¸‹è¦è‡ªå·±æ›´æ­£ä¸€ä¸‹:"""

few_shot_examples = [
    dspy.Example({'question': q["question"], 'answer': q["answer"]}) for q in dataset
]

trainset = [x.with_inputs('question') for x in few_shot_examples]

"""DSPy çš„ code: å®šç¾© prompt çš„çµæ§‹"""

class QuestionLabel(dspy.Signature):
    question = dspy.InputField(desc="The input question to be categorized")
    answer = dspy.OutputField(desc="The assigned category or label for the question")

class QuestionClassification(dspy.Module):
    def __init__(self):
        super().__init__()
        self.classifier = dspy.Predict(QuestionLabel)

    def forward(self, question: str):
        return self.classifier(question=question)

"""MIProv2 å„ªåŒ–å™¨çš„æ–‡ä»¶: https://dspy-docs.vercel.app/docs/deep-dive/optimizers/miprov2

è©•ä¼°æ¡ç”¨å…§å»ºçš„ answer_exact_match æ–¹æ³•ï¼Œæœ‰æ¨™æº–ç­”æ¡ˆï¼Œå°±æª¢æŸ¥æ˜¯å¦ä¸€æ¨¡ä¸€æ¨£å³å¯
"""

teleprompter = MIPROv2(prompt_model=prompt_llm, task_model=task_llm, metric=answer_exact_match, num_candidates=10, init_temperature=1, verbose=True)

# é–‹å§‹è·‘æœ€ä½³åŒ–è¿­ä»£
compiled_program = teleprompter.compile(QuestionClassification(), trainset=trainset, requires_permission_to_run=False)

"""## 4. æœ€å¾Œçµæœ

DSPy ä¸åªæ˜¯æœ€ä½³åŒ–å·¥å…·ï¼Œæœ¬èº«å°±æ˜¯ä¸€å€‹åŸ·è¡Œæ¡†æ¶
"""

compiled_program('ç­é•·æœ‰ä»€éº¼äº†ä¸èµ·ï¼Œæˆ‘å°å­¸ä¹Ÿç•¶éç­é•·å•Š!')

"""å¯ä»¥æŠŠæœ€ä½³åŒ–åƒæ•¸å­˜ä¸‹ä¾†ï¼Œä¸‹æ¬¡è¼‰å…¥ä½¿ç”¨"""

compiled_program.save("compiled_program.json")

"""è§€å¯Ÿæœ€å¾Œçš„æœ€ä½³åŒ– prompt:"""

print( task_llm.inspect_history(1) )

